{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_multiple_linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CazISR8X_HUG"
      },
      "source": [
        "# Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "844TSK4Swelq"
      },
      "source": [
        "# same like single linear, but this regression have more than one independant variable\n",
        "# formula of MLR is y = b + m1x1 + m2x2 +...+ mnxn\n",
        "# y is dependant variable\n",
        "# b is intercept\n",
        "# m is coefficient\n",
        "# x is independant variable\n",
        "# n is how many indepandant variable exist in case\n",
        "\n",
        "# to use linear regression, we must have several assumptions:\n",
        "# data is linear, homoscedasticity, multivariate normality, independence of errors, \n",
        "# lack of multicollinearity\n",
        "# all of these must true before we can use linear regression\n",
        "\n",
        "# in this startup case, we have 3 independant variable that have same value (dollars amount)\n",
        "# but we also have state, which is categorical data so we have make dummy variables to this category.\n",
        "# the technique to make dummy variable is like one-hot encoding,\n",
        "# one-hot encoding make n variable based on n category\n",
        "# dummy variable make n-1 variable based on n category\n",
        "# ex: 2 category, new york, california, miami, LA\n",
        "# dummy var : newyork 1 0 0, california 0 1 0, miami 0 0 1, LA 0 0 0\n",
        "# one-hot : newyork 1 0 0 0, california 0 1 0 0, miami 0 0 1 0, LA 0 0 0 1\n",
        "\n",
        "# dummy variable trap\n",
        "# why dummy variable only use n-1 variable? because of dummy variable trap\n",
        "# dummy variable trap can happen because of multicollinearity.\n",
        "# in simple term it happen because one variable can explain other variable.\n",
        "# using our example, by using only 0 0 0 data, we already know that the data is LA.\n",
        "# we dont need 0 0 0 1 to represent LA.\n",
        "# the effect is in linear regression, every variable is have individual coefficient,\n",
        "# if we have 0 0 0 1, when 1 occur it also have coefficient in which already stated as intercept.\n",
        "# the solution of this is by remove the last variable, or remove intercept.\n",
        "\n",
        "# p values\n",
        "# p values is a value in hypothesis testing to help support or rejecting the null hypothesis \n",
        "# smaller p values, stronger evidence to reject hypothesis\n",
        "# we get p values from calculation\n",
        "\n",
        "# building model\n",
        "# some of independent values have to thrown out.\n",
        "# reason 1 : garbage in, garbage out, too many independent is bad\n",
        "# reason 2 : variable have to be explained, and how it can affect dependant variable\n",
        "# only keep most important variable to be independent variable\n",
        "\n",
        "# to build model, we can use several method\n",
        "\n",
        "# all in, use all variable\n",
        "# when to use : prior knowledge, have to, prepare for backward elimination\n",
        "\n",
        "# backward elimination\n",
        "# 1. select significance level\n",
        "# 2. fit full model with all possible predictors\n",
        "# 3. consider the predictor with the highest p value, if p value > significance level, remove the predictor\n",
        "# else fin\n",
        "# 4. fit model without this variable, back to step 3\n",
        "\n",
        "# forward elimination\n",
        "# 1. select significance level\n",
        "# 2. fit all simple regression models, select one with the lowest p value\n",
        "# 3. keep this variable, and fit with extra predictor added.\n",
        "# 4. consider the predictor with lowest p value, if p value < significance level, back to step 3\n",
        "# else fin, keep the previous model without new predictor added.\n",
        "\n",
        "# bidirectional elimination\n",
        "# 1. select significance level to enter & significance level to stay\n",
        "# 2. perform the next step of forward selection\n",
        "# 3. perform all step from backward elimination, back to step 2, until no new variable can enter & old exit\n",
        "# model ready\n",
        "\n",
        "# all possible models\n",
        "# like bruteforce, resourceful but accurate\n",
        "# construct all possible models.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOyqYHTk_Q57"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiWInpqKR7w8"
      },
      "source": [
        "# import all module\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgC61-ah_WIz"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP-FxrxFSKlr"
      },
      "source": [
        "# import dataset from file\n",
        "dataset = pd.read_csv('50_Startups.csv')\n",
        "x = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1:].values"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwG0sPhdWyJB",
        "outputId": "f23006ea-001d-4721-9942-d403b4c5ed07"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[165349.2 136897.8 471784.1 'New York']\n [162597.7 151377.59 443898.53 'California']\n [153441.51 101145.55 407934.54 'Florida']\n [144372.41 118671.85 383199.62 'New York']\n [142107.34 91391.77 366168.42 'Florida']\n [131876.9 99814.71 362861.36 'New York']\n [134615.46 147198.87 127716.82 'California']\n [130298.13 145530.06 323876.68 'Florida']\n [120542.52 148718.95 311613.29 'New York']\n [123334.88 108679.17 304981.62 'California']\n [101913.08 110594.11 229160.95 'Florida']\n [100671.96 91790.61 249744.55 'California']\n [93863.75 127320.38 249839.44 'Florida']\n [91992.39 135495.07 252664.93 'California']\n [119943.24 156547.42 256512.92 'Florida']\n [114523.61 122616.84 261776.23 'New York']\n [78013.11 121597.55 264346.06 'California']\n [94657.16 145077.58 282574.31 'New York']\n [91749.16 114175.79 294919.57 'Florida']\n [86419.7 153514.11 0.0 'New York']\n [76253.86 113867.3 298664.47 'California']\n [78389.47 153773.43 299737.29 'New York']\n [73994.56 122782.75 303319.26 'Florida']\n [67532.53 105751.03 304768.73 'Florida']\n [77044.01 99281.34 140574.81 'New York']\n [64664.71 139553.16 137962.62 'California']\n [75328.87 144135.98 134050.07 'Florida']\n [72107.6 127864.55 353183.81 'New York']\n [66051.52 182645.56 118148.2 'Florida']\n [65605.48 153032.06 107138.38 'New York']\n [61994.48 115641.28 91131.24 'Florida']\n [61136.38 152701.92 88218.23 'New York']\n [63408.86 129219.61 46085.25 'California']\n [55493.95 103057.49 214634.81 'Florida']\n [46426.07 157693.92 210797.67 'California']\n [46014.02 85047.44 205517.64 'New York']\n [28663.76 127056.21 201126.82 'Florida']\n [44069.95 51283.14 197029.42 'California']\n [20229.59 65947.93 185265.1 'New York']\n [38558.51 82982.09 174999.3 'California']\n [28754.33 118546.05 172795.67 'California']\n [27892.92 84710.77 164470.71 'Florida']\n [23640.93 96189.63 148001.11 'California']\n [15505.73 127382.3 35534.17 'New York']\n [22177.74 154806.14 28334.72 'California']\n [1000.23 124153.04 1903.93 'New York']\n [1315.46 115816.21 297114.46 'Florida']\n [0.0 135426.92 0.0 'California']\n [542.05 51743.15 0.0 'New York']\n [0.0 116983.8 45173.06 'California']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOrkdqHuW725"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[192261.83]\n [191792.06]\n [191050.39]\n [182901.99]\n [166187.94]\n [156991.12]\n [156122.51]\n [155752.6 ]\n [152211.77]\n [149759.96]\n [146121.95]\n [144259.4 ]\n [141585.52]\n [134307.35]\n [132602.65]\n [129917.04]\n [126992.93]\n [125370.37]\n [124266.9 ]\n [122776.86]\n [118474.03]\n [111313.02]\n [110352.25]\n [108733.99]\n [108552.04]\n [107404.34]\n [105733.54]\n [105008.31]\n [103282.38]\n [101004.64]\n [ 99937.59]\n [ 97483.56]\n [ 97427.84]\n [ 96778.92]\n [ 96712.8 ]\n [ 96479.51]\n [ 90708.19]\n [ 89949.14]\n [ 81229.06]\n [ 81005.76]\n [ 78239.91]\n [ 77798.83]\n [ 71498.49]\n [ 69758.98]\n [ 65200.33]\n [ 64926.08]\n [ 49490.75]\n [ 42559.73]\n [ 35673.41]\n [ 14681.4 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VadrvE7s_lS9"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvAIZPMzZCrL"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ct= ColumnTransformer(transformers = [('encoder', OneHotEncoder(),[3])],remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x))\n",
        "\n",
        "# we don't have to do feature scaling, because every variable have it own coefficient\n",
        "# we don't need to check linear regression assumption because it will be a waste of time\n",
        "# and if it don't have linear variable so it will give poor accuracy and we must use other model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WemVnqgeA70k"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRUUMNl0ZGnQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-McZVsQBINc"
      },
      "source": [
        "## Training the Multiple Linear Regression model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vDKmgY0X5VT",
        "outputId": "3a83121a-47f6-48ac-d87d-a6b513e4805a"
      },
      "source": [
        "# we don't have to do something to avoid dummy variable trap\n",
        "# because the class that will be used in this step will automatically avoid dummy variable trap.\n",
        "# so we only need to prepare encoded category to one-hot encoding\n",
        "\n",
        "# we don't have to determine which combination of variable that have p value needed because the class also automatically take care that problem.\n",
        "# the MLR class automatically search the highest accuracy.\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "\n",
        "lr.fit(x_train,y_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNkXL1YQBiBT"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkUVroO1aWSi",
        "outputId": "c1797c84-3a01-49ba-f6b5-4f55ae8ab3b2"
      },
      "source": [
        "y_pred = lr.predict(x_test)\n",
        "\n",
        "#set decimal precision\n",
        "np.set_printoptions(precision = 2)\n",
        "\n",
        "# concatenate vertically / horizontally from 2 set of data\n",
        "# reshape the vector to 1 column\n",
        "# concatenate axis set to 1 to vertical concatenate, 0 to horizontal (default)\n",
        "# if want concat vertical, the result must be shaped to vertical, vice versa\n",
        "print(np.concatenate((y_pred.reshape(1,len(y_pred)),y_test.reshape(1,len(y_test)))))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[126362.88  84608.45  99677.49  46357.46 128750.48  50912.42 109741.35\n  100643.24  97599.28 113097.43]\n [134307.35  81005.76  99937.59  64926.08 125370.37  35673.41 105733.54\n  107404.34  97427.84 122776.86]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgQfGFwWd0xm",
        "outputId": "01391734-e8c6-4af6-b2d1-6fd5ddfc9852"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[126362.88]\n [ 84608.45]\n [ 99677.49]\n [ 46357.46]\n [128750.48]\n [ 50912.42]\n [109741.35]\n [100643.24]\n [ 97599.28]\n [113097.43]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XqRhexdafwG",
        "outputId": "0a652dde-b1d6-4590-efaf-da79c38ace67"
      },
      "source": [
        "print(y_pred.reshape(1,len(y_pred)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[126362.88  84608.45  99677.49  46357.46 128750.48  50912.42 109741.35\n  100643.24  97599.28 113097.43]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiDUotvSaiI9",
        "outputId": "ecea553f-7eaa-4b06-dae5-a8e182af3314"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[134307.35]\n [ 81005.76]\n [ 99937.59]\n [ 64926.08]\n [125370.37]\n [ 35673.41]\n [105733.54]\n [107404.34]\n [ 97427.84]\n [122776.86]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRjWDwPrcbwI",
        "outputId": "43e7e1aa-f7d3-4780-e7e3-701e641a51da"
      },
      "source": [
        "print(y_test.reshape(1,len(y_test)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[134307.35  81005.76  99937.59  64926.08 125370.37  35673.41 105733.54\n  107404.34  97427.84 122776.86]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3oB91TigtQw",
        "outputId": "d6cd6ee5-7972-435c-d3d1-c10202162af9"
      },
      "source": [
        "print(lr.coef_)\n",
        "print(lr.intercept_)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.15e+02  6.24e+02 -3.08e+02  8.06e-01 -6.88e-02  2.99e-02]]\n[54343.3]\n"
          ]
        }
      ]
    }
  ]
}