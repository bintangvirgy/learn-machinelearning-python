{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_multiple_linear_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bintangvirgy/learn-machinelearning-python/blob/main/03_multiple_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CazISR8X_HUG"
      },
      "source": [
        "# Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "844TSK4Swelq"
      },
      "source": [
        "# same like single linear, but this regression have more than one independant variable\n",
        "# formula of MLR is y = b + m1x1 + m2x2 +...+ mnxn\n",
        "# y is dependant variable\n",
        "# b is intercept\n",
        "# m is coefficient\n",
        "# x is independant variable\n",
        "# n is how many indepandant variable exist in case\n",
        "\n",
        "# to use linear regression, we must have several assumptions:\n",
        "# data is linear, homoscedasticity, multivariate normality, independence of errors, \n",
        "# lack of multicollinearity\n",
        "# all of these must true before we can use linear regression\n",
        "\n",
        "# in this startup case, we have 3 independant variable that have same value (dollars amount)\n",
        "# but we also have state, which is categorical data so we have make dummy variables to this category.\n",
        "# the technique to make dummy variable is like one-hot encoding,\n",
        "# one-hot encoding make n variable based on n category\n",
        "# dummy variable make n-1 variable based on n category\n",
        "# ex: 2 category, new york, california, miami, LA\n",
        "# dummy var : newyork 1 0 0, california 0 1 0, miami 0 0 1, LA 0 0 0\n",
        "# one-hot : newyork 1 0 0 0, california 0 1 0 0, miami 0 0 1 0, LA 0 0 0 1\n",
        "\n",
        "# dummy variable trap\n",
        "# why dummy variable only use n-1 variable? because of dummy variable trap\n",
        "# dummy variable trap can happen because of multicollinearity.\n",
        "# in simple term it happen because one variable can explain other variable.\n",
        "# using our example, by using only 0 0 0 data, we already know that the data is LA.\n",
        "# we dont need 0 0 0 1 to represent LA.\n",
        "# the effect is in linear regression, every variable is have individual coefficient,\n",
        "# if we have 0 0 0 1, when 1 occur it also have coefficient in which already stated as intercept.\n",
        "# the solution of this is by remove the last variable, or remove intercept.\n",
        "\n",
        "# p values\n",
        "# p values is a value in hypothesis testing to help support or rejecting the null hypothesis \n",
        "# smaller p values, stronger evidence to reject hypothesis\n",
        "# we get p values from calculation\n",
        "\n",
        "# building model\n",
        "# some of independent values have to thrown out.\n",
        "# reason 1 : garbage in, garbage out, too many independent is bad\n",
        "# reason 2 : variable have to be explained, and how it can affect dependant variable\n",
        "# only keep most important variable to be independent variable\n",
        "\n",
        "# to build model, we can use several method\n",
        "\n",
        "# all in, use all variable\n",
        "# when to use : prior knowledge, have to, prepare for backward elimination\n",
        "\n",
        "# backward elimination\n",
        "# 1. select significance level\n",
        "# 2. fit full model with all possible predictors\n",
        "# 3. consider the predictor with the highest p value, if p value > significance level, remove the predictor\n",
        "# else fin\n",
        "# 4. fit model without this variable, back to step 3\n",
        "\n",
        "# forward elimination\n",
        "# 1. select significance level\n",
        "# 2. fit all simple regression models, select one with the lowest p value\n",
        "# 3. keep this variable, and fit with extra predictor added.\n",
        "# 4. consider the predictor with lowest p value, if p value < significance level, back to step 3\n",
        "# else fin, keep the previous model without new predictor added.\n",
        "\n",
        "# bidirectional elimination\n",
        "# 1. select significance level to enter & significance level to stay\n",
        "# 2. perform the next step of forward selection\n",
        "# 3. perform all step from backward elimination, back to step 2, until no new variable can enter & old exit\n",
        "# model ready\n",
        "\n",
        "# all possible models\n",
        "# like bruteforce, resourceful but accurate\n",
        "# construct all possible models.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGPKRQeKRr8d",
        "outputId": "933074b1-6565-49af-b8f7-0f27754f50a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOyqYHTk_Q57"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiWInpqKR7w8"
      },
      "source": [
        "# import all module\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgC61-ah_WIz"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP-FxrxFSKlr"
      },
      "source": [
        "# import dataset from file\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Learn_Machinelearning_Udemy/03.Multi_linear_regression/50_Startups.csv')\n",
        "x = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1:].values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwG0sPhdWyJB",
        "outputId": "f23006ea-001d-4721-9942-d403b4c5ed07"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
            " [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n",
            " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
            " [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
            " [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n",
            " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
            " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
            " [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n",
            " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
            " [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n",
            " [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n",
            " [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n",
            " [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n",
            " [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n",
            " [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n",
            " [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n",
            " [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n",
            " [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n",
            " [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n",
            " [0.0 0.0 1.0 86419.7 153514.11 0.0]\n",
            " [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n",
            " [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n",
            " [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n",
            " [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n",
            " [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n",
            " [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n",
            " [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n",
            " [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n",
            " [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n",
            " [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n",
            " [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n",
            " [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n",
            " [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n",
            " [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n",
            " [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n",
            " [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n",
            " [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n",
            " [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n",
            " [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n",
            " [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n",
            " [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n",
            " [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n",
            " [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n",
            " [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n",
            " [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n",
            " [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n",
            " [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n",
            " [1.0 0.0 0.0 0.0 135426.92 0.0]\n",
            " [0.0 0.0 1.0 542.05 51743.15 0.0]\n",
            " [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOrkdqHuW725"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VadrvE7s_lS9"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvAIZPMzZCrL"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ct= ColumnTransformer(transformers = [('encoder', OneHotEncoder(),[3])],remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x))\n",
        "\n",
        "# we don't have to do feature scaling, because every variable have it own coefficient\n",
        "# we don't need to check linear regression assumption because it will be a waste of time\n",
        "# and if it don't have linear variable so it will give poor accuracy and we must use other model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WemVnqgeA70k"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRUUMNl0ZGnQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-McZVsQBINc"
      },
      "source": [
        "## Training the Multiple Linear Regression model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vDKmgY0X5VT",
        "outputId": "3a83121a-47f6-48ac-d87d-a6b513e4805a"
      },
      "source": [
        "# we don't have to do something to avoid dummy variable trap\n",
        "# because the class that will be used in this step will automatically avoid dummy variable trap.\n",
        "# so we only need to prepare encoded category to one-hot encoding\n",
        "\n",
        "# we don't have to determine which combination of variable that have p value needed because the class also automatically take care that problem.\n",
        "# the MLR class automatically search the highest accuracy.\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lr = LinearRegression()\n",
        "\n",
        "lr.fit(x_train,y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNkXL1YQBiBT"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkUVroO1aWSi",
        "outputId": "c1797c84-3a01-49ba-f6b5-4f55ae8ab3b2"
      },
      "source": [
        "y_pred = lr.predict(x_test)\n",
        "\n",
        "#set decimal precision\n",
        "np.set_printoptions(precision = 2)\n",
        "\n",
        "# concatenate vertically / horizontally from 2 set of data\n",
        "# reshape the vector to 1 column\n",
        "# concatenate axis set to 1 to vertical concatenate, 0 to horizontal (default)\n",
        "# if want concat vertical, the result must be shaped to vertical, vice versa\n",
        "print(np.concatenate((y_pred.reshape(1,len(y_pred)),y_test.reshape(1,len(y_test)))))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[126362.88  84608.45  99677.49  46357.46 128750.48  50912.42 109741.35\n",
            "  100643.24  97599.28 113097.43]\n",
            " [134307.35  81005.76  99937.59  64926.08 125370.37  35673.41 105733.54\n",
            "  107404.34  97427.84 122776.86]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgQfGFwWd0xm",
        "outputId": "01391734-e8c6-4af6-b2d1-6fd5ddfc9852"
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[126362.87908251]\n",
            " [ 84608.45383642]\n",
            " [ 99677.49425153]\n",
            " [ 46357.4606858 ]\n",
            " [128750.48288498]\n",
            " [ 50912.41741903]\n",
            " [109741.35032699]\n",
            " [100643.24281643]\n",
            " [ 97599.27574598]\n",
            " [113097.42524436]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XqRhexdafwG",
        "outputId": "0a652dde-b1d6-4590-efaf-da79c38ace67"
      },
      "source": [
        "print(y_pred.reshape(1,len(y_pred)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[126362.88  84608.45  99677.49  46357.46 128750.48  50912.42 109741.35\n",
            "  100643.24  97599.28 113097.43]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiDUotvSaiI9",
        "outputId": "ecea553f-7eaa-4b06-dae5-a8e182af3314"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[134307.35]\n",
            " [ 81005.76]\n",
            " [ 99937.59]\n",
            " [ 64926.08]\n",
            " [125370.37]\n",
            " [ 35673.41]\n",
            " [105733.54]\n",
            " [107404.34]\n",
            " [ 97427.84]\n",
            " [122776.86]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRjWDwPrcbwI",
        "outputId": "43e7e1aa-f7d3-4780-e7e3-701e641a51da"
      },
      "source": [
        "print(y_test.reshape(1,len(y_test)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[134307.35  81005.76  99937.59  64926.08 125370.37  35673.41 105733.54\n",
            "  107404.34  97427.84 122776.86]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3oB91TigtQw",
        "outputId": "d6cd6ee5-7972-435c-d3d1-c10202162af9"
      },
      "source": [
        "print(lr.coef_)\n",
        "print(lr.intercept_)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-3.15e+02  6.24e+02 -3.08e+02  8.06e-01 -6.88e-02  2.99e-02]]\n",
            "[54343.3]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}