{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_data_preprocessing_tools.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bintangvirgy/learn-machinelearning-python/blob/main/01_data_preprocessing_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sxPJRpoc3S-"
      },
      "source": [
        "# preprocessing step is the most important step in ML modelling.\n",
        "# in preprocessing step, we prepare datasets which will be used in create ML Model.\n",
        "# two main step in data preprocessing :\n",
        "# 1. Importing the dataset \n",
        "# 2. splitting the dataset into train set and test set : 2 main dataset include feature & label\n",
        "\n",
        "# we may be used other step depend on what kind of data \n",
        "# encoding categorical data : transform the string based value to number, because ML can't process string data\n",
        "# fill missing data : filling null data with some strategy (ex: mean of all other value)\n",
        "# feature scaling : transform unscaled data and make sure all data have same scale \n",
        "#                   (ex: amount and ages data exist on same dataset, it must be transformed to same scale)\n",
        "\n",
        "# *Feature is independant variable, variable that determine label\n",
        "# *label is dependant variable, variable that determined by feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqBw_S-Aod_y",
        "outputId": "7c5d9b25-e08c-4758-e4a6-f350b7a70cbc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Iu9Z_nxugg4"
      },
      "source": [
        "# this is the basic library for data processing in python\n",
        "import numpy as np # for work with array\n",
        "import matplotlib.pyplot as pl # for make graph chart & visualize data\n",
        "import pandas as pd # for import & make matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJZSvJaFvqW3"
      },
      "source": [
        "# import and create data frame to process\n",
        "# pandas automatically make first row as col name\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Learn_Machinelearning_Udemy/01.preprocessing_data/01_preprocessing_data.csv') \n",
        "\n",
        "# container for matrix of feature (feature is column used to make prediction)\n",
        "# use function iloc to get location of feature col (1-3)(all except last one)\n",
        "# first one is extract row, second one is extract column (imagine the dataset is formed like 2d matrix)\n",
        "# if we use 1d matrix, we just need [:], if 2d [:, :]\n",
        "x_feature = dataset.iloc[:, :-1].values\n",
        "\n",
        "# container for dependant variable (depandant is what ML want to predict)\n",
        "y_dependant = dataset.iloc[:, -1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n7zz0eHzzMN"
      },
      "source": [
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLdH-I4r2dbB"
      },
      "source": [
        "print(x_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBz9G3vA2fDL"
      },
      "source": [
        "print(y_dependant)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohOm35l_jeE5"
      },
      "source": [
        "# change all missing data with average of all other row in same column\n",
        "\n",
        "# use scikitlearn module, most of common used module in datascience & ML (read imputer)\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# initiate class of imputer\n",
        "# set parameter missing_values to not found cell (nan value), to declare nan values use np.nan\n",
        "# set parameter strategy to what can of action we want to do if missing_value is found\n",
        "var_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "# add pre transformed matrix to imputer\n",
        "# select all x_feature row, on column age & salary (column age is on index 1 & 2, so slice on 1:3, from index 1 to before index 3)\n",
        "var_imputer.fit(x_feature[:, 1:3])\n",
        "\n",
        "# execute transformation and put result on original matrix\n",
        "x_feature[:, 1:3] = var_imputer.transform(x_feature[:, 1:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1-nGhENr6un"
      },
      "source": [
        "print(x_feature)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsrUDIyyuZW_"
      },
      "source": [
        "# we have 2 column of data that written in string (country and purchased), \n",
        "# ML can't recognize string value, so we must encode it to number  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh"
      },
      "source": [
        "### Encoding the Independent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krKL67g9wmI9"
      },
      "source": [
        "# for country column\n",
        "# first idea is turn france = 0, spain = 1, germany = 2, but if we do this \n",
        "# ML can interpret this column as ordered number.\n",
        "# Other idea is one-hot encoding(let's google it), by make 3 column because we have 3 category\n",
        "# so french = 100, spain 010, germany = 001\n",
        "\n",
        "# to one-hot encoding use 2 clases\n",
        "# column transfrom class\n",
        "from sklearn.compose import ColumnTransformer\n",
        "# one-hot class\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# declare object column transformer\n",
        "# transformer : what kind of transformation, what kind of encoding, index column (in tuple)\n",
        "# remainder : parameter to keep or not to keep others column that not transformed\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "\n",
        "# fit & transform the matrix and keep it in old variable\n",
        "# and make result as numpy array because ML use numpy array\n",
        "x_feature = np.array(ct.fit_transform(x_feature))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFFX6bA5zxEe",
        "outputId": "c7298e78-9a63-4961-c0d0-77b64643ec64"
      },
      "source": [
        "print(x_feature)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXh8oVSITIc6"
      },
      "source": [
        "\n",
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZIPY4L00YoD"
      },
      "source": [
        "# for purchased column\n",
        "# we don't need to one-hot this column because it only have 2 category\n",
        "# so we just need to label it\n",
        "\n",
        "# import label encoder class\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# declare object label encoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# fit and transform matrix\n",
        "# label encoder don't need transform to np array because it already np array\n",
        "y_dependant = le.fit_transform(y_dependant) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXgbo4471URp",
        "outputId": "e5110dc4-12ed-4503-96f7-aae96d84b23f"
      },
      "source": [
        "print(y_dependant)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp3HxUBLRcnU"
      },
      "source": [
        "# training set : set of data that used to train the ML model\n",
        "# test set : set of data that used to test the accuracy of ML model\n",
        "# we use sklearn module to split the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 4 container for result, x train, y train, x test, y test\n",
        "# train_test_split use x_feature and y_dependant as parameter, not a complete dataset\n",
        "# test_size : size of test part in scale 0-1, if we make it 0.3 then the train set will be 0.7\n",
        "# random_state : make sure selection of set will be random\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_feature, y_dependant, test_size = 0.2, random_state = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yxoq5fRWhll",
        "outputId": "76f516b8-ba7a-4aa6-c8f1-fef89cdb1951"
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj_C-gGhWhtW",
        "outputId": "5acd8a98-f152-40a7-dcfe-d6f02aac13d6"
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN06fQDNWh0r",
        "outputId": "1bf42f4e-7f4e-412b-f600-a732adf9d8a8"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dx7R4LeWh6w",
        "outputId": "af913bfe-596c-4bf0-8a28-c05f3c4a52a1"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDnK5gEPRq86"
      },
      "source": [
        "# when feature scaling done is still debatable\n",
        "# this tutorial recommend to do feature scaling after splitting dataset\n",
        "# because test set is supposed to be a new brand set that tested after model deployed\n",
        "# and feature scaling is done by using all the dataset to fit. \n",
        "# Logically, the test set must follow the model scale, not determine the model scale.\n",
        "# Both test & train data must be scale, but only train data that allowed to determine the model scale.\n",
        "\n",
        "# feature scaling is used to scaling all feature to make sure that all feature have same scale\n",
        "# and there isn't a feature that dominate other feature\n",
        "# 2 common scaling technique\n",
        "# standardisation : x-mean(x)/ standard deviation of x, resulting value between -3 to +3\n",
        "# normalisation : x - min(x)/ max(x) - min(x), resulting value 0 to 1\n",
        "# normalisation is used when we have normal distribution in most feature\n",
        "# standardisation work well all the time \n",
        "\n",
        "# we only use feature scaling on uncategorized variable\n",
        "# because we already encoded category to 3 values, if we do scaling on this feature, we will lost it information\n",
        "\n",
        "# we use standardisation on this tutorial\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# declare object\n",
        "sc = StandardScaler()\n",
        "\n",
        "# get only 2 last column (from col 3)\n",
        "# we make a scale by fitting the train test & transform it values to determined scale\n",
        "x_train[:, 3:] = sc.fit_transform((x_train[:, 3:]))\n",
        "# transform test data to determined scale\n",
        "x_test[:, 3:] = sc.transform((x_test[:, 3:]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efO0g19oclM8",
        "outputId": "7cc55305-d717-4c79-ddc0-5576342cde96"
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhVVTyOKclQD",
        "outputId": "aef0f654-577d-4ddc-c7b9-c38f6d0c617b"
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}